\documentclass[letterpaper,10pt]{article}

%\usepackage[top=1.5in,bottom=1.5in,left=1in,right=1in]{geometry}
\usepackage{amsmath}
\usepackage{amstext}
\usepackage{dcolumn}
\usepackage{courier}
\usepackage{listings}
\usepackage[usenames,dvipsnames]{color}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{array}
\usepackage{tikz-qtree}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[T1]{fontenc}
\usepackage{enumitem}

% Syntax highliting
\lstset{
    language=C++,
    basicstyle=\ttfamily\small,
    breaklines=true,
    prebreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
    frame=lines,
    showtabs=false,
    showspaces=false,
    showstringspaces=false,
    keywordstyle=\color{Dandelion}\textbf,
    stringstyle=\color{BrickRed},
    commentstyle=\color{gray}\itshape,
    numbers=left,
    captionpos=t,
    escapeinside={\%*}{*)},
    belowskip=1em,
}

\newcolumntype{d}[1]{D{.}{.}{#1} }

\newcommand{\fref}[1]{Figure~\ref{#1}}

\title{
  \LARGE CS 484: Application Research Project Proposal \\
  \Huge Clustering Validation on Textual Dataset \\
}
\author{Jean Michel Rouly \& Joshua Wells }
\date{\today}




\begin{document}

\maketitle

\section{Problem Statement}

One of the most common types of data on the Internet today is
human-generated textual data. This data comes with many different internal
patterns and possible categorizations. Identifying patterns and subsets
within an otherwise unknown large dataset is a difficult problem, addressed
namely by the application of clustering algorithms.

There are a great deal of clustering algorithms which can be applied to
these datasets, many of which have been implemented using scientific Python
libraries. Validating the performance and overall quality of these
algorithms can be difficult on large data sets, especially as many of these
data sets do not have a connected ground-truth.

Current state-of-the-art techniques include K-Means, Affinity Propagation,
Mean-Shift, Spectral Clustering, Hierarchical Clustering (multiple
techniques), DBSCAN, and Gaussian Mixtures. Many of these algorithms have
pros and cons over different data set structures and patterns.  We would
like to determine how these algorithm classes apply to large data sets of
human text with a great deal of variation in size of clusters and a large
number of total clusters.


\section{Datasets}

\begin{tabular}{lll}
\textbf{URL} & \textbf{Name} & \textbf{Size} \\
\hline
archive.org/details/stackexchange  & StackExchange Data Dump & 184 GB \\
\end{tabular}

\subsection{StackExchange Data Dump}

StackExchange is a major online community where users can post questions
within some field, and other users respond and answer. Posts in each field
range in complexity from general questions to sophisticated, technical
inquiries. There are several thousand posts in each category (around 20GB
data average, ranging up to several hundred) and 230 class labels
(\textit{i.e.} different fields).


\section{Procedure}

\begin{itemize}
  \item Preprocess the data
    \begin{itemize}
    \item Parse out questions from data set, generate flat file structure
    \item Generate TF-IDF vectors from data points, generate similarity
    matrix (using \texttt{scikit-learn})
    \end{itemize}
  \item Perform analytics
    \begin{itemize}
    \item Run multiple clustering algorithms (those listed above) and keep
    track of data point cluster membership. \texttt{scikit-learn} will be
    useful in this process
    \end{itemize}
  \item Evaluate performance
    \begin{itemize}
    \item Using \texttt{matplotlib} generate visualizations
    \item Perform accuracy metrics against ground-truth labels from the
    initial data set
    \end{itemize}
\end{itemize}

\section{Evaluation Methodologies}

Because clustering is an inherently unsupervised process, it can be
difficult to evaluate performance. Additionally, these algorithms can be
applied to a variety of different structures of data with varying results.
We will evaluate algorithmic performance over a particular type of data
commonly found on the Internet by clustering a data set and analyzing
performance accuracy against a ground-truth set of labels.

\nocite{*}

\bibliographystyle{plain}
\bibliography{rouly_wells_proposal}

\end{document}
