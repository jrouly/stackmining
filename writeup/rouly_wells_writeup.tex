\documentclass[letterpaper,10pt]{article}

\usepackage[fleqn]{amsmath}
\usepackage{amstext}
\usepackage{dcolumn}
\usepackage{courier}
\usepackage{listings}
\usepackage{color}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{array}
\usepackage{multirow}
\usepackage{amssymb}
\usepackage{pifont}
\usepackage{enumitem}
\usepackage[normalem]{ulem}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\DeclareMathSymbol{\mlq}{\mathord}{operators}{``}
\DeclareMathSymbol{\mrq}{\mathord}{operators}{`'}

% Syntax highliting
\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    breaklines=true,
    prebreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
    frame=none,
    showtabs=false,
    showspaces=false,
    showstringspaces=false,
    keywordstyle=\color{Dandelion}\textbf,
    stringstyle=\color{BrickRed},
    commentstyle=\color{gray}\itshape,
    numbers=left,
    captionpos=t,
    escapeinside={\%*}{*)},
    morekeywords={minus},
}

\newcolumntype{d}[1]{D{.}{.}{#1} }

\newcommand{\fref}[1]{Figure~\ref{#1}}

\title{
  \Huge\textbf{Mining StackExchange} \\
  \LARGE Data Mining Final Project \\
  CS 484 \\
}
\author{
  Jean Michel Rouly\\
  \texttt{jrouly@gmu.edu}
  \and
  Joshua Wells\\
  \texttt{jwells@gmu.edu}
}
\date{\today}

\begin{document}

\maketitle


  \section{Problem Description}

  Textual data is everywhere on the Internet today. This written language
  data comes in a wide variety of differing sizes, structures, reading
  levels, languages, and character sets. Identifying patterns and
  sub-structure in a large, unknown data space like this is a formidable
  problem. And yet, because of textual data's ubiquity and value, it is one
  of the most important problems to solve efficiently and effectively. Data
  mining tools based on machine learning techniques provide a possible
  solution to this problem.

  Because of the unknown nature of large, Internet sourced textual
  datasets, the most readily applicable algorithms for data investigation
  are ``unsupervised'' clustering algorithms. These algorithms are
  considered unsupervised because, generally, no initial knowledge about
  the dataset is required. Thus they serve as excellent tools to perform
  preliminary investigation on an unknown dataset. However, given knowledge
  about the dataset (\textit{e.g.} a ground-truth set of labels over the
  data) other algorithms can become relevant. There are a variety of
  powerful classification algorithms which can be applied to large textual
  data sets when the labels of a subset of training data are known
  beforehand.

  The goal of this project is to apply a variety of data mining techniques,
  specifically clustering and classifying algorithms, to a large dataset of
  textual, natural-language data. The dataset used is the archived
  collection of posts from
  StackExchange.\footnote{\url{http://stackexchange.com}} Several different
  algorithms will be applied and their performance compared on this
  prototypical Internet sourced textual dataset. A secondary goal of this
  investigation is to showcase some of the features of the Python machine
  learning library
  \texttt{scikit-learn}.\footnote{\url{http://scikit-learn.org}}


  \section{Related Work}

  How does this problem and the method relate to problems/methods others
  have developed in the past.


  \section{Solution}

  How did you solve the problem? Describe the technical approach. Tell us
  what method/algorithm did you use, develop or extend and how did you
  implement it.


  \section{Experiments}

  \subsection{Data} Briefly describe the data and its size (number of
  records and number of features, type of features etc.)

  \subsection{Experimental Setup} Describe how did you setup your
  experiments, how the training/testing data was prepared, what performance
  metrics are you considering, what baseline methods for comparison are you
  using.

  \subsection{Experimental Results} Describe your experimental results.
  Structure your experiments around particular aspects of your method. For
  example, you could structure the experiment as follows: (1) a table
  showing results of your method using different types of features; (2)
  table comparing the performance of your method to the baseline; (3) a
  graph plotting the size of the training dataset vs. the time it takes to
  train the model; (4) Investigation of the learned model (what are the
  important features, etc.). \cite{santos2009}


  \section{Conclusion}


  \section{Contributions}

  \input{josh_contributions}
  \input{michel_contributions}

  \clearpage
  \bibliographystyle{plain}
  \bibliography{rouly_wells_writeup}


\end{document}
